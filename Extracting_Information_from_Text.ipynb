{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting Information from Text.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mMjNJarVaJ6",
        "colab_type": "text"
      },
      "source": [
        "### Reference\n",
        "\n",
        "http://www.nltk.org/book/ch07.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svlJoZGKNcWh",
        "colab_type": "text"
      },
      "source": [
        "### Information Extraction from structured date \n",
        "\n",
        "      More like a database with tables storing all the information which are of interest . \n",
        "      | Org Name       | Location |\n",
        "      |----------      |----------|\n",
        "      |Omnicom \t    |New York  |\n",
        "      |DDB Needham     |New York  | \n",
        "      |Kaplan Thaler   |New York  |\n",
        "      |BBDO South      |Atlanta   |\n",
        "      |Georgia-Pacific |Atlanta   |\n",
        "      \n",
        "      \n",
        "      \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEODtURCNQK9",
        "colab_type": "code",
        "outputId": "fe987a3e-157e-4e89-d032-071bb073d2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "locs = [('Omnicom', 'IN', 'New York'),('DDB Needham', 'IN', 'New York'),\n",
        "         ('Kaplan Thaler Group', 'IN', 'New York'),\n",
        "        ('BBDO South', 'IN', 'Atlanta'),\n",
        "         ('Georgia-Pacific', 'IN', 'Atlanta')]\n",
        "\n",
        "# Showing organization name along with location \n",
        "\n",
        "# Which organizations operate in Atlanta? \n",
        "\n",
        "query = [ e1 for(e1,e2,e3) in locs if e3=='Atlanta' ]\n",
        "query\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BBDO South', 'Georgia-Pacific']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4LE0D-WTgAc",
        "colab_type": "text"
      },
      "source": [
        "Information Extraction usually deals with unstructured data as in \n",
        "\n",
        "\n",
        "  **(1)The fourth Wells account moving to another agency is the packaged paper-products division of Georgia-Pacific Corp., which arrived at Wells only last fall. Like Hertz and the History Channel, it is also leaving for an Omnicom-owned agency, the BBDO South unit of BBDO Worldwide. BBDO South in Atlanta, which handles corporate advertising for Georgia-Pacific, will assume additional duties for brands like Angel Soft toilet tissue and Sparkle paper towels, said Ken Haldin, a spokesman for Georgia-Pacific in Atlanta.**\n",
        "  \n",
        "  \n",
        "  Approaches include \n",
        "  ____________________________\n",
        " \n",
        " 1) General Representation of Meaning\n",
        " \n",
        " 2)  Convert Unstructured data to Structured data \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39c_CpyvUjVB",
        "colab_type": "text"
      },
      "source": [
        "### Block Diagram of Information Extraction\n",
        "\n",
        "  ![alt-text](http://www.nltk.org/images/ie-architecture.png )\n",
        "  \n",
        "  Relation Detection is used to identify the relations between entities recognized during Named Entity Recognition (NER)\n",
        "  \n",
        "  \n",
        "  The first three stages the preprocessing phase can be done using the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFwWNUntPa94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "def pre_process(document):\n",
        "  sentences = nltk.sent_tokenize(document) \n",
        "  words= [nltk.word_tokenize(sent) for sent in sentences] \n",
        "  pos_tagg = [nltk.pos_tag(word) for word in words] \n",
        "  return pos_tagg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2UXo4fkXJWf",
        "colab_type": "code",
        "outputId": "bf91792c-13e0-405a-c40d-edd558b38d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjX3EjXeV7a8",
        "colab_type": "code",
        "outputId": "9434be5d-6655-4510-801a-1f37660476dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Testing with random sentence \n",
        "document = \"The phone comes with an in-display fingerprint scanner and a water drop notch on the display.\"\n",
        "print(pre_process(document))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('The', 'DT'), ('phone', 'NN'), ('comes', 'VBZ'), ('with', 'IN'), ('an', 'DT'), ('in-display', 'JJ'), ('fingerprint', 'NN'), ('scanner', 'NN'), ('and', 'CC'), ('a', 'DT'), ('water', 'NN'), ('drop', 'NN'), ('notch', 'NN'), ('on', 'IN'), ('the', 'DT'), ('display', 'NN'), ('.', '.')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arl9WqRlYzES",
        "colab_type": "text"
      },
      "source": [
        "  Next comes the named entity recognition phase \n",
        "    Named Entities include\n",
        "  \n",
        "  _________________\n",
        "  \n",
        "  *  Proper Noun (Like names of Persons ,Objects )\n",
        "  \n",
        "  Relation Extraction usually takes place between named entities that are closer to one another ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfvAZasWWOVY",
        "colab_type": "text"
      },
      "source": [
        "## Chunking\n",
        "\n",
        "  Smaller boxes show world level tokenization and parts of speech tagging . Larger boxes show high level chunking\n",
        "  ![alt-text](http://www.nltk.org/images/chunk-segmentation.png)\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US9e6EOiWw4b",
        "colab_type": "text"
      },
      "source": [
        "### Noun Phrase Chunking \n",
        "\n",
        "In NP Chunking we search for chunks corresponding to Noun Phrase\n",
        "\n",
        "[The dog ] barked at [the cat]  \n",
        "    Phrases within square brackets are noun phrase chunks \n",
        "    \n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRSYkUm2XHO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9284657-4346-4014-f181-66730c1f7506"
      },
      "source": [
        "# Create an NP Chunk Parser \n",
        "\n",
        "# Get tagging from function pre_process\n",
        "\n",
        "document = \"The old man walked slowly with a stick .\"\n",
        "tagged_words = pre_process(document)\n",
        "print(tagged_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('walked', 'VBD'), ('slowly', 'RB'), ('with', 'IN'), ('a', 'DT'), ('stick', 'NN'), ('.', '.')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGL3xPpuhOsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5YMJPPUZDB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "076f97cd-9e4a-4ce5-f3bf-3bbc3a7151aa"
      },
      "source": [
        "# A Noun Phrase is formed by a determiner followed by the noun\n",
        "\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"     # The rule  NP -> DETERMINER (ADJECTIVE)* NOUN\n",
        "\n",
        "\n",
        "# Create our chunk parser \n",
        "\n",
        "chunk_parser = nltk.RegexpParser(grammar)\n",
        "result = chunk_parser.parse(tagged_words[0])\n",
        "print(result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP The/DT old/JJ man/NN)\n",
            "  walked/VBD\n",
            "  slowly/RB\n",
            "  with/IN\n",
            "  (NP a/DT stick/NN)\n",
            "  ./.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIwd2OZZhVwZ",
        "colab_type": "text"
      },
      "source": [
        " A tag pattern is a sequence of part-of-speech tags delimited using angle brackets,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qoKNYyPho-C",
        "colab_type": "text"
      },
      "source": [
        "### Chunking using Regular Expression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0af5uXKiDGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d693f87b-76fb-4d69-fb85-df35d8dea3e7"
      },
      "source": [
        "grammar = r\"\"\"\n",
        "          NP : {<DT|PP\\$>?<JJ>*<NN>}\n",
        "               {<NNP>+}\n",
        "          \"\"\"\n",
        "chunk_parser = nltk.RegexpParser(grammar)\n",
        "\n",
        "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), \n",
        "                 (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n",
        "\n",
        "print(chunk_parser.parse(sentence))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP Rapunzel/NNP)\n",
            "  let/VBD\n",
            "  down/RP\n",
            "  (NP her/PP$ long/JJ golden/JJ hair/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfsD77BrijAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40bd5b5b-c9e5-4607-8fd0-2bc02879281b"
      },
      "source": [
        "# Overlapping  chunking\n",
        "\n",
        "new_tag_words = pre_process(\"money market fund\")[0]\n",
        "grammar = \"NP:{<NN><NN>}\"\n",
        "parser = nltk.RegexpParser(grammar)\n",
        "print(parser.parse(new_tag_words))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S (NP money/NN market/NN) fund/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McejoUoci4ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}